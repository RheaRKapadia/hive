{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key='')\n",
    "pc.create_index(\n",
    "    name='exercise-db', dimension=1536, metric='cosine', spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://exercisedb.p.rapidapi.com/exercises\"\n",
    "\n",
    "querystring = {\"limit\":\"1400\",\"offset\":\"0\"}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"\",\n",
    "\t\"x-rapidapi-host\": \"exercisedb.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "exercise_data = requests.get(url, headers=headers, params=querystring)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/rag/lib/python3.10/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/rag/lib/python3.10/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/rag/lib/python3.10/site-packages (from requests) (2024.7.4)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "Installing collected packages: charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-3.3.2 requests-2.32.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_data = exercise_data.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "processed_data = []\n",
    "openai.api_key = ''\n",
    "index = pc.Index('exercise-db')\n",
    "batch_size = 100\n",
    "for exercise in exercise_data:\n",
    "    # Combine relevant fields into a single string for embedding\n",
    "    combined_text = f\"{exercise['name']} {exercise['target']} {' '.join(exercise['equipment'])}\"\n",
    "    \n",
    "    # Get the embedding for the combined text\n",
    "    response = openai.embeddings.create(\n",
    "        input=combined_text,\n",
    "        model='text-embedding-3-small'\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    \n",
    "    # Prepare the data for Pinecone\n",
    "    processed_data.append({\n",
    "        'id': exercise['id'],\n",
    "        'values': embedding,\n",
    "        'metadata': {\n",
    "            'name': exercise['name'],\n",
    "            'target': exercise['target'],\n",
    "            'secondaryMuscles': exercise['secondaryMuscles'],\n",
    "            'instructions': exercise['instructions'],\n",
    "            'equipment': exercise['equipment']\n",
    "        }\n",
    "    })\n",
    "    # Upsert in batches\n",
    "    if len(processed_data) >= batch_size:\n",
    "        index.upsert(vectors=processed_data)\n",
    "        processed_data = []  # Clear the list after upserting\n",
    "\n",
    "# Upsert any remaining data\n",
    "if processed_data:\n",
    "    index.upsert(vectors=processed_data)\n",
    "\n",
    "\n",
    "# # Index the data in Pinecone\n",
    "# pc.upsert(vectors=processed_data)\n",
    "\n",
    "# print(\"Data indexed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
